{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w, b):\n",
    "    return w * t_u + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 손실 함수 설정 (mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000,\n",
       "        21.8000, 48.4000, 60.4000, 68.4000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.ones(())\n",
    "b = torch.zeros(())\n",
    "\n",
    "t_p = model(t_u, w , b)\n",
    "t_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1763.8848)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(t_p, t_c)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손실 줄이기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 편미분 공식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias 값\n",
    "delta = 0.1\n",
    "\n",
    "loss_rate_of_change_w = (loss_fn(model(t_u, w + delta,b), t_c) - loss_fn(model(t_u, w + delta,b), t_c)) / (2.0 * delta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "learning_rate = 1e-2\n",
    "\n",
    "w = w - learning_rate * loss_rate_of_change_w\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.8260)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_rate_of_change_b = (loss_fn(model(t_u, w, b + delta), t_c) - loss_fn(model(t_u, w,b - delta), t_c)) / (2.0 * delta) \n",
    "b = b - learning_rate * loss_rate_of_change_b\n",
    "b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MSE 공식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(t_p , t_c):\n",
    "    squared_diffs = (t_p - t_c) ** 2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE를 미분하여 모델 파라미터의 기울기를 구할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dloss_fn(t_p , t_c):\n",
    "    dsq_diff = 2 * (t_p - t_c)  / t_p.size(0)\n",
    "    return dsq_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델에 미분 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "def model(t_u , w , b):\n",
    "    return t_u * w + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 가중치 w 에 대한 편미분\n",
    "    - t_u * w  + b 공식에서 w 에 대한 편미분을 진행했으므로 t_u 만 남는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmodel_dw(t_u, w , b):\n",
    "    return t_u\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 편향 b에 대한 편미분\n",
    "    - t_u * w 공식에서 b에 대한 편미분을 진행햤는데 b는 상수이므로 1.0 만 남는다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmodel_db(t_u, w , b):\n",
    "    return 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경사 함수 정의\n",
    "- 모델이 학습할 때 필요한 기울기 계산\n",
    "- 모델의 파라미터에 대한 손실 함수의 기울기를 계산\n",
    "- 미분 연쇄 법칙이 적용\n",
    "    - 복합함수의 미분을 구할 때 각 함수의 미분을 곱하는 방법\n",
    "    - 여기서는 weight 와 bias 가 기울기(mse의 미분값)와 곱해진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_fn(t_u ,t_c, t_p, w , b):\n",
    "    dloss_dtp = dloss_fn(t_p, t_c)\n",
    "    dloss_dw = dloss_dtp * dmodel_dw(t_u, w , b)\n",
    "    dloss_db = dloss_dtp *  dmodel_db(t_u, w , b)\n",
    "    return torch.stack([dloss_dw.sum(), dloss_db.sum()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 적합을 위하여 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs , learning_rate , params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        w , b = params\n",
    "        \n",
    "        t_p = model(t_u , w , b) #순방향 전달\n",
    "        loss = loss_fn(t_p , t_c) #Mean squeared Error\n",
    "        grad = grad_fn(t_u ,t_c, t_p, w , b) #역방향 전달\n",
    "\n",
    "        # 파라미터 조정\n",
    "        params = params - learning_rate * grad\n",
    "\n",
    "        print(f'Epoch : {epoch}  Loss : {loss:.2f}  Grad : {grad}')\n",
    "    return params\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef training_loop(n_epochs, learning_rate, params, t_u, t_c,\\n                  print_params=True):\\n    for epoch in range(1, n_epochs + 1):\\n        w, b = params\\n\\n        t_p = model(t_u, w, b)  # <1>\\n        loss = loss_fn(t_p, t_c)\\n        grad = grad_fn(t_u, t_c, t_p, w, b)  # <2>\\n\\n        params = params - learning_rate * grad\\n\\n        if epoch in {1, 2, 3, 10, 11, 99, 100, 4000, 5000}:  # <3>\\n            print('Epoch %d, Loss %f' % (epoch, float(loss)))\\n            if print_params:\\n                print('    Params:', params)\\n                print('    Grad:  ', grad)\\n        if epoch in {4, 12, 101}:\\n            print('...')\\n\\n        if not torch.isfinite(loss).all():\\n            break  # <3>\\n            \\n    return params\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c,\n",
    "                  print_params=True):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        w, b = params\n",
    "\n",
    "        t_p = model(t_u, w, b)  # <1>\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        grad = grad_fn(t_u, t_c, t_p, w, b)  # <2>\n",
    "\n",
    "        params = params - learning_rate * grad\n",
    "\n",
    "        if epoch in {1, 2, 3, 10, 11, 99, 100, 4000, 5000}:  # <3>\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "            if print_params:\n",
    "                print('    Params:', params)\n",
    "                print('    Grad:  ', grad)\n",
    "        if epoch in {4, 12, 101}:\n",
    "            print('...')\n",
    "\n",
    "        if not torch.isfinite(loss).all():\n",
    "            break  # <3>\n",
    "            \n",
    "    return params\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 휸련 진행\n",
    "- loss가 무한대가 되어버린다\n",
    "- params 조정이 너무 크다는 신호\n",
    "    - 값이 앞뒤로 진동하면서 조정 값이 점점 커진다\n",
    "- 최적화는 불안정해지고 , 수렴이 아닌 발산 해버린다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop(\n",
    "    n_epochs = 100 ,\n",
    "    learning_rate = 1e-2 , \n",
    "    params = torch.tensor([1.0 ,0.0]), \n",
    "    t_u = t_u, \n",
    "    t_c = t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 해결방법\n",
    "- learning_rate 를 줄인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as no\n",
    "training_loop(\n",
    "    n_epochs = 100 ,\n",
    "    learning_rate = 1e-4 , \n",
    "    params = torch.tensor([1.0 ,0.0]), \n",
    "    t_u = t_u, \n",
    "    t_c = t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위의 코드에서 가중치에 대한 기울기는 편향에 대한 기울기보다 약 50배정도 큼\n",
    "    - 가중치와 편향값의 범위가 다르다는 뜻\n",
    "    - 각각 범위를 조정하지 않고 t_u 값을 정규화 해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_un = t_u * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as no\n",
    "training_loop(\n",
    "    n_epochs = 100 ,\n",
    "    learning_rate = 1e-2 , \n",
    "    params = torch.tensor([1.0 ,0.0]), \n",
    "    t_u = t_un, \n",
    "    t_c = t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* parmams 값의 변화량이 줄어들 때까지 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as no\n",
    "training_loop(\n",
    "    n_epochs = 5000 ,\n",
    "    learning_rate = 1e-2 , \n",
    "    params = torch.tensor([1.0 ,0.0]), \n",
    "    t_u = t_un, \n",
    "    t_c = t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/bin/python\n",
      "Python 3.12.2\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "t_p = model(t_un, *params)  # <1>\n",
    "\n",
    "fig = plt.figure(dpi=600)\n",
    "plt.xlabel(\"Temperature (°Fahrenheit)\")\n",
    "plt.ylabel(\"Temperature (°Celsius)\")\n",
    "plt.plot(t_u.numpy(), t_p.detach().numpy()) # <2>\n",
    "plt.plot(t_u.numpy(), t_c.numpy(), 'o')\n",
    "plt.savefig(\"temp_unknown_plot.png\", format=\"png\")  # bookskip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
